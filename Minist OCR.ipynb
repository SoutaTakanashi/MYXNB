{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33fa2f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training set...\n",
      "叮！图像转换完成！赞美太阳！\n",
      "Building test set...\n",
      "叮！图像转换完成！赞美太阳！\n"
     ]
    }
   ],
   "source": [
    "#Step1:Convert original file into jpg in different folders.\n",
    "import os\n",
    "from skimage import io\n",
    "import torchvision.datasets.mnist as mnist\n",
    "\n",
    "train_set = (\n",
    "mnist.read_image_file('gzip\\emnist-mnist-train-images-idx3-ubyte\\emnist-mnist-train-images-idx3-ubyte'),\n",
    "mnist.read_label_file('gzip\\emnist-mnist-train-labels-idx1-ubyte\\emnist-mnist-train-labels-idx1-ubyte')\n",
    ")\n",
    "test_set = (\n",
    "    mnist.read_image_file('gzip\\emnist-mnist-test-images-idx3-ubyte\\emnist-mnist-test-images-idx3-ubyte'),\n",
    "    mnist.read_label_file('gzip\\emnist-mnist-test-labels-idx1-ubyte\\emnist-mnist-test-labels-idx1-ubyte')\n",
    ")\n",
    "#They are in 'tensor' type.\n",
    "\n",
    "#print(train_set[0][1])\n",
    "# 从原始数据 到 jpg图片 顺便装到文件夹里面\n",
    "def convert_to_img(train=True):\n",
    "    \n",
    "    if train:  # 如果是训练数据\n",
    "        # 注意这里路径的写法，对就是/符号\n",
    "        f = open('train.txt', 'w')\n",
    "        data_path ='train/' # 好像可以删去左边的/\n",
    "        # 如果不存在就新建\n",
    "        if not os.path.exists(data_path):\n",
    "            os.makedirs(data_path)\n",
    "            # enumerate将可遍历对象 组合成索引 可加参数start=2 索引从2开始\n",
    "        for i, (img, label) in enumerate(zip(train_set[0], train_set[1])):\n",
    "            img_path = data_path+str(i)+'.jpg'\n",
    "            # 保存图片\n",
    "            io.imsave(img_path, img.numpy())\n",
    "            # 保存标号文件路径和标号\n",
    "            f.write(img_path + ' ' + str(label.item()) + '\\n')\n",
    "\n",
    "        f.close()\n",
    "    else:\n",
    "        f = open('test.txt', 'w')\n",
    "        data_path ='test/'\n",
    "        if not os.path.exists(data_path):\n",
    "            os.makedirs(data_path)\n",
    "        for i, (img, label) in enumerate(zip(test_set[0], test_set[1])):\n",
    "            img_path = data_path + str(i) + '.jpg'\n",
    "            io.imsave(img_path, img.numpy())\n",
    "            f.write(img_path + ' ' + str(label.item()) + '\\n')\n",
    "        f.close()\n",
    "\n",
    "\n",
    "if os.path.exists('train'): #如果目录不存在就返回False\n",
    "    print(\"Pictures(train) already converted.\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"Building training set...\")\n",
    "    convert_to_img(True)\n",
    "    print(\"叮！图像转换完成！赞美太阳！\")\n",
    "\n",
    "if os.path.exists('test'):  # 如果目录不存在就返回False\n",
    "    print(\"Pictures(test) already converted.\")\n",
    "else:\n",
    "    print(\"Building test set...\")\n",
    "    convert_to_img(False)\n",
    "    print(\"叮！图像转换完成！赞美太阳！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ad0a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    # txt是路径和文件名\n",
    "    def __init__(self, txt, transform=transforms.ToTensor(), target_transform=None, loader=default_loader):\n",
    "        fh = open(txt, 'r')  # 只读打开\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "\n",
    "            line = line.strip('\\n')  # 删除 回车\n",
    "            line = line.rstrip()  # 删除 右侧 空格\n",
    "            words = line.split()  # 分割：就两列，0列是路径 1列是标号\n",
    "\n",
    "            imgs.append((words[0], int(words[1])))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader  # 是个函数\n",
    "\n",
    "    # train_loader里面的\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]   # fn是完整路径 label是标号\n",
    "        img = self.loader(fn)  # 调用上面的default_loader(path) 按照路径读取图片\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)  # 将图片转换成FloatTensor类型\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3f1e009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train_data...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'tensor(4)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16428/3428263909.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Reading train_data...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# from torch.utils.data import Dataset, DataLoader 下面的函数在这里\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Reading test_data...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16428/1340897477.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, txt, transform, target_transform, loader)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 分割：就两列，0列是路径 1列是标号\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'tensor(4)'"
     ]
    }
   ],
   "source": [
    "print(\"Reading train_data...\")\n",
    "train_data = MyDataset(txt='train.txt', transform=transforms.ToTensor())\n",
    "# from torch.utils.data import Dataset, DataLoader 下面的函数在这里\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=50, shuffle=True)\n",
    "print(\"Reading test_data...\")\n",
    "test_data = MyDataset(txt='test.txt', transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # (1,28,28)\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5,\n",
    "                      stride=1, padding=2),  # (16,28,28)\n",
    "            # 想要con2d卷积出来的图片尺寸没有变化, padding=(kernel_size-1)/2\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)  # (16,14,14)\n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "           torch.nn.Conv2d(32, 64, 3, 1, 1),\n",
    "           torch.nn.ReLU(),\n",
    "           torch.nn.MaxPool2d(2)\n",
    "       )\n",
    "        self.conv3 = torch.nn.Sequential(\n",
    "           torch.nn.Conv2d(64, 64, 3, 1, 1),\n",
    "           torch.nn.ReLU(),\n",
    "           torch.nn.MaxPool2d(2)\n",
    "       )\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)  # 将（batch，32,7,7）展平为（batch，32*7*7）\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9935d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失\n",
    "model = Net()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    start = time.time()\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x, requires_grad=False)\n",
    "        b_y = Variable(y, requires_grad=False)\n",
    "        # if if_use_gpu:\n",
    "        b_x = b_x\n",
    "        b_y = b_y\n",
    "        print(step)\n",
    "        output = model(b_x)\n",
    "        loss = loss_function(output, b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print('Epoch:', epoch, '|Step:', step,\n",
    "                  '|train loss:%d' % loss.item())\n",
    "\n",
    "#测试\n",
    "test_output = model(test_x)\n",
    "pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "print(pred_y,test_y)\n",
    "accuracy = sum(pred_y == test_y) / test_y.size(0)\n",
    "print('Test Acc: %.4f'%accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
